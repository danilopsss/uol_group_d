{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3452c949-b7a4-4cb6-af2b-dc9280d861dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with Mean Imputation:\n",
      "    Year  Grid ID 2019  LAEI 1km2 ID  Easting  Northing  Borough     Zone  \\\n",
      "0  2030             1          5910   510500    203500  Non GLA  Non GLA   \n",
      "1  2030             2          5911   511500    203500  Non GLA  Non GLA   \n",
      "2  2030             3          5912   512500    203500  Non GLA  Non GLA   \n",
      "3  2030             4          5915   515500    203500  Non GLA  Non GLA   \n",
      "4  2030             5          5916   516500    203500  Non GLA  Non GLA   \n",
      "\n",
      "  Main Source Category   Sector        Source  ...  n2o  nh3  nmvoc  nox  pb  \\\n",
      "0             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "1             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "2             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "3             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "4             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "\n",
      "   pcb      pm10     pm2.5  so2  Emissions Unit  \n",
      "0  NaN  0.019183  0.019183  NaN    tonnes/annum  \n",
      "1  NaN  0.015719  0.015719  NaN    tonnes/annum  \n",
      "2  NaN  0.019878  0.019878  NaN    tonnes/annum  \n",
      "3  NaN  0.020946  0.020946  NaN    tonnes/annum  \n",
      "4  NaN  0.020105  0.020105  NaN    tonnes/annum  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Data with Median Imputation:\n",
      "    Year  Grid ID 2019  LAEI 1km2 ID  Easting  Northing  Borough     Zone  \\\n",
      "0  2030             1          5910   510500    203500  Non GLA  Non GLA   \n",
      "1  2030             2          5911   511500    203500  Non GLA  Non GLA   \n",
      "2  2030             3          5912   512500    203500  Non GLA  Non GLA   \n",
      "3  2030             4          5915   515500    203500  Non GLA  Non GLA   \n",
      "4  2030             5          5916   516500    203500  Non GLA  Non GLA   \n",
      "\n",
      "  Main Source Category   Sector        Source  ...  n2o  nh3  nmvoc  nox  pb  \\\n",
      "0             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "1             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "2             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "3             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "4             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "\n",
      "   pcb      pm10     pm2.5  so2  Emissions Unit  \n",
      "0  NaN  0.019183  0.019183  NaN    tonnes/annum  \n",
      "1  NaN  0.015719  0.015719  NaN    tonnes/annum  \n",
      "2  NaN  0.019878  0.019878  NaN    tonnes/annum  \n",
      "3  NaN  0.020946  0.020946  NaN    tonnes/annum  \n",
      "4  NaN  0.020105  0.020105  NaN    tonnes/annum  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "### Load and Process the Files\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "file_mean = \"/Users/dianenacario/scikit_learn_data/uol_group_d/datasets_mean_median/LAEI_2019_NA_FILLED_WITH_MEAN.csv\"\n",
    "file_median = \"/Users/dianenacario/scikit_learn_data/uol_group_d/datasets_mean_median/LAEI_2019_NA_FILLED_WITH_MEDIAN.csv\"\n",
    "\n",
    "# Load the datasets\n",
    "mean_df = pd.read_csv(file_mean)\n",
    "median_df = pd.read_csv(file_median)\n",
    "\n",
    "# Check the first few rows of each dataset\n",
    "print(\"Data with Mean Imputation:\\n\", mean_df.head())\n",
    "print(\"\\nData with Median Imputation:\\n\", median_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60c4ad4-d067-4913-9080-3d9c86217afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Data (Mean Imputation):\n",
      "         Year  Grid ID 2019  LAEI 1km2 ID  Easting  Northing  Borough     Zone  \\\n",
      "285264  2019             1          5910   510500    203500  Non GLA  Non GLA   \n",
      "285265  2019             2          5911   511500    203500  Non GLA  Non GLA   \n",
      "285266  2019             3          5912   512500    203500  Non GLA  Non GLA   \n",
      "285267  2019             4          5915   515500    203500  Non GLA  Non GLA   \n",
      "285268  2019             5          5916   516500    203500  Non GLA  Non GLA   \n",
      "\n",
      "       Main Source Category   Sector        Source  ...  n2o  nh3  nmvoc  nox  \\\n",
      "285264             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "285265             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "285266             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "285267             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "285268             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "\n",
      "        pb  pcb      pm10     pm2.5  so2  Emissions Unit  \n",
      "285264 NaN  NaN  0.021923  0.021923  NaN    tonnes/annum  \n",
      "285265 NaN  NaN  0.017965  0.017965  NaN    tonnes/annum  \n",
      "285266 NaN  NaN  0.022718  0.022718  NaN    tonnes/annum  \n",
      "285267 NaN  NaN  0.023939  0.023939  NaN    tonnes/annum  \n",
      "285268 NaN  NaN  0.022977  0.022977  NaN    tonnes/annum  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "Filtered Data (Median Imputation):\n",
      "         Year  Grid ID 2019  LAEI 1km2 ID  Easting  Northing  Borough     Zone  \\\n",
      "285264  2019             1          5910   510500    203500  Non GLA  Non GLA   \n",
      "285265  2019             2          5911   511500    203500  Non GLA  Non GLA   \n",
      "285266  2019             3          5912   512500    203500  Non GLA  Non GLA   \n",
      "285267  2019             4          5915   515500    203500  Non GLA  Non GLA   \n",
      "285268  2019             5          5916   516500    203500  Non GLA  Non GLA   \n",
      "\n",
      "       Main Source Category   Sector        Source  ...  n2o  nh3  nmvoc  nox  \\\n",
      "285264             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "285265             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "285266             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "285267             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "285268             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "\n",
      "        pb  pcb      pm10     pm2.5  so2  Emissions Unit  \n",
      "285264 NaN  NaN  0.021923  0.021923  NaN    tonnes/annum  \n",
      "285265 NaN  NaN  0.017965  0.017965  NaN    tonnes/annum  \n",
      "285266 NaN  NaN  0.022718  0.022718  NaN    tonnes/annum  \n",
      "285267 NaN  NaN  0.023939  0.023939  NaN    tonnes/annum  \n",
      "285268 NaN  NaN  0.022977  0.022977  NaN    tonnes/annum  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "### Filter Data for 2013, 2016, 2019\n",
    "\n",
    "# Filter dataset to include only years 2013, 2016, and 2019 for training\n",
    "train_data_mean = mean_df[mean_df['Year'].isin([2013, 2016, 2019])]\n",
    "train_data_median = median_df[median_df['Year'].isin([2013, 2016, 2019])]\n",
    "\n",
    "# Check if filtering worked\n",
    "print(\"Filtered Data (Mean Imputation):\\n\", train_data_mean.head())\n",
    "print(\"Filtered Data (Median Imputation):\\n\", train_data_median.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17ea61d4-7e75-420b-bd79-3415a95610a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process Categorical Variables\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the Label Encoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Encode 'Main Source Category' using explicit row and column indexing\n",
    "train_data_mean.loc[:, \"main_source_encoded\"] = encoder.fit_transform(train_data_mean.loc[:, \"Main Source Category\"])\n",
    "train_data_median.loc[:, \"main_source_encoded\"] = encoder.fit_transform(train_data_median.loc[:, \"Main Source Category\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0041c9c1-cdb9-433c-8e71-da33fdc80064",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Handle Missing Values\n",
    "\n",
    "# Fill missing values with the mean for the mean-imputed dataset\n",
    "for col in [\"nox\", \"pm10\", \"pm2.5\", \"co2\"]:\n",
    "    train_data_mean.loc[:, col] = train_data_mean[col].fillna(train_data_mean[col].mean())\n",
    "\n",
    "# Fill missing values with the median for the median-imputed dataset\n",
    "for col in [\"nox\", \"pm10\", \"pm2.5\", \"co2\"]:\n",
    "    train_data_median.loc[:, col] = train_data_median[col].fillna(train_data_median[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b9d53ac-317c-4b2b-869b-0950f26025ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Data for Model Training\n",
    "# Define the years for training and testing\n",
    "train_years = [2013, 2016, 2019]\n",
    "test_year = 2025\n",
    "\n",
    "# Define the pollutants to predict\n",
    "pollutants = [\"nox\", \"pm10\", \"pm2.5\", \"co2\"]\n",
    "\n",
    "# Prepare the features (X) by dropping target variables and Year\n",
    "X_train_mean = train_data_mean[train_data_mean[\"Year\"].isin(train_years)].drop(columns=pollutants + [\"Year\"])\n",
    "X_test_mean = train_data_mean[train_data_mean[\"Year\"] == test_year].drop(columns=pollutants + [\"Year\"])\n",
    "\n",
    "X_train_median = train_data_median[train_data_median[\"Year\"].isin(train_years)].drop(columns=pollutants + [\"Year\"])\n",
    "X_test_median = train_data_median[train_data_median[\"Year\"] == test_year].drop(columns=pollutants + [\"Year\"])\n",
    "\n",
    "# Prepare the target variables (y) for both the training and testing sets\n",
    "# Using a dictionary to store the targets for each pollutant\n",
    "y_train_mean = {pollutant: train_data_mean[train_data_mean[\"Year\"].isin(train_years)][pollutant] for pollutant in pollutants}\n",
    "y_test_mean = {pollutant: train_data_mean[train_data_mean[\"Year\"] == test_year][pollutant] for pollutant in pollutants}\n",
    "\n",
    "y_train_median = {pollutant: train_data_median[train_data_median[\"Year\"].isin(train_years)][pollutant] for pollutant in pollutants}\n",
    "y_test_median = {pollutant: train_data_median[train_data_median[\"Year\"] == test_year][pollutant] for pollutant in pollutants}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81a992da-45d4-4ada-a7ef-df32e9096656",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-Hot Encoding of Categorical Variables\n",
    "# Since the Main Source Category and potentially other categorical variables are present, \n",
    "# we need to encode these for model training using One-Hot Encoding\n",
    "\n",
    "# One-Hot Encode the categorical variables in both training and testing sets\n",
    "X_train_mean_encoded = pd.get_dummies(X_train_mean, drop_first=True)\n",
    "X_test_mean_encoded = pd.get_dummies(X_test_mean, drop_first=True)\n",
    "\n",
    "X_train_median_encoded = pd.get_dummies(X_train_median, drop_first=True)\n",
    "X_test_median_encoded = pd.get_dummies(X_test_median, drop_first=True)\n",
    "\n",
    "# Ensure the columns in the training and testing sets match\n",
    "X_train_mean_encoded, X_test_mean_encoded = X_train_mean_encoded.align(X_test_mean_encoded, join='left', axis=1, fill_value=0)\n",
    "X_train_median_encoded, X_test_median_encoded = X_train_median_encoded.align(X_test_median_encoded, join='left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e6c0ca1-201e-4837-9169-809ac7e2816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the target variables (y) for both the training and testing sets\n",
    "pollutants = [\"nox\", \"pm10\", \"pm2.5\", \"co2\"]\n",
    "\n",
    "y_train_mean = {pollutant: train_data_mean[train_data_mean[\"Year\"].isin(train_years)][pollutant] for pollutant in pollutants}\n",
    "y_test_mean = {pollutant: train_data_mean[train_data_mean[\"Year\"] == test_year][pollutant] for pollutant in pollutants}\n",
    "\n",
    "y_train_median = {pollutant: train_data_median[train_data_median[\"Year\"].isin(train_years)][pollutant] for pollutant in pollutants}\n",
    "y_test_median = {pollutant: train_data_median[train_data_median[\"Year\"] == test_year][pollutant] for pollutant in pollutants}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a6c3f-a901-4f2c-b92e-b5b2616354ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Random Forest Model for each pollutants\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Define pollutants to train the model for\n",
    "pollutants = [\"nox\", \"pm10\", \"pm2.5\", \"co2\"]\n",
    "\n",
    "# Function to train Random Forest for each pollutant\n",
    "def train_rf_for_all_pollutants(X_train_mean, X_train_median, train_data_mean, train_data_median, pollutants):\n",
    "    # Store the models for each pollutant\n",
    "    models_mean = {}\n",
    "    models_median = {}\n",
    "    \n",
    "    for pollutant in pollutants:\n",
    "        # Prepare the target variable for the current pollutant\n",
    "        y_train_mean = train_data_mean[train_data_mean[\"Year\"].isin([2013, 2016, 2019])][pollutant]\n",
    "        y_train_median = train_data_median[train_data_median[\"Year\"].isin([2013, 2016, 2019])][pollutant]\n",
    "        \n",
    "        # Apply One-Hot Encoding to the training sets\n",
    "        X_train_mean_encoded = pd.get_dummies(X_train_mean, drop_first=True)\n",
    "        X_train_median_encoded = pd.get_dummies(X_train_median, drop_first=True)\n",
    "\n",
    "        # Train the model using the mean-imputed dataset\n",
    "        rf_model_mean = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        rf_model_mean.fit(X_train_mean_encoded, y_train_mean)\n",
    "        models_mean[pollutant] = rf_model_mean  # Save the trained model\n",
    "\n",
    "        # Train the model using the median-imputed dataset\n",
    "        rf_model_median = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        rf_model_median.fit(X_train_median_encoded, y_train_median)\n",
    "        models_median[pollutant] = rf_model_median  # Save the trained model\n",
    "\n",
    "        print(f\"Training completed for pollutant: {pollutant}\")\n",
    "    \n",
    "    return models_mean, models_median\n",
    "\n",
    "# Prepare the training features (X_train) from 2013, 2016, and 2019\n",
    "X_train_mean = train_data_mean[train_data_mean[\"Year\"].isin([2013, 2016, 2019])].drop(columns=pollutants + [\"Year\"])\n",
    "X_train_median = train_data_median[train_data_median[\"Year\"].isin([2013, 2016, 2019])].drop(columns=pollutants + [\"Year\"])\n",
    "\n",
    "# Train Random Forest models for each pollutant\n",
    "models_mean, models_median = train_rf_for_all_pollutants(X_train_mean, X_train_median, train_data_mean, train_data_median, pollutants)\n",
    "\n",
    "# Now models_mean and models_median store the trained Random Forest models for each pollutant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac14be6-63b9-4b18-be5f-6cc944fa2c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
