{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99fb434c-a5b2-4f2d-bc29-e91120283420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with Mean Imputation:\n",
      "    Year  Grid ID 2019  LAEI 1km2 ID  Easting  Northing  Borough     Zone  \\\n",
      "0  2030             1          5910   510500    203500  Non GLA  Non GLA   \n",
      "1  2030             2          5911   511500    203500  Non GLA  Non GLA   \n",
      "2  2030             3          5912   512500    203500  Non GLA  Non GLA   \n",
      "3  2030             4          5915   515500    203500  Non GLA  Non GLA   \n",
      "4  2030             5          5916   516500    203500  Non GLA  Non GLA   \n",
      "\n",
      "  Main Source Category   Sector        Source  ...  n2o  nh3  nmvoc  nox  pb  \\\n",
      "0             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "1             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "2             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "3             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "4             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "\n",
      "   pcb      pm10     pm2.5  so2  Emissions Unit  \n",
      "0  NaN  0.019183  0.019183  NaN    tonnes/annum  \n",
      "1  NaN  0.015719  0.015719  NaN    tonnes/annum  \n",
      "2  NaN  0.019878  0.019878  NaN    tonnes/annum  \n",
      "3  NaN  0.020946  0.020946  NaN    tonnes/annum  \n",
      "4  NaN  0.020105  0.020105  NaN    tonnes/annum  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Data with Median Imputation:\n",
      "    Year  Grid ID 2019  LAEI 1km2 ID  Easting  Northing  Borough     Zone  \\\n",
      "0  2030             1          5910   510500    203500  Non GLA  Non GLA   \n",
      "1  2030             2          5911   511500    203500  Non GLA  Non GLA   \n",
      "2  2030             3          5912   512500    203500  Non GLA  Non GLA   \n",
      "3  2030             4          5915   515500    203500  Non GLA  Non GLA   \n",
      "4  2030             5          5916   516500    203500  Non GLA  Non GLA   \n",
      "\n",
      "  Main Source Category   Sector        Source  ...  n2o  nh3  nmvoc  nox  pb  \\\n",
      "0             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "1             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "2             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "3             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "4             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN NaN   \n",
      "\n",
      "   pcb      pm10     pm2.5  so2  Emissions Unit  \n",
      "0  NaN  0.019183  0.019183  NaN    tonnes/annum  \n",
      "1  NaN  0.015719  0.015719  NaN    tonnes/annum  \n",
      "2  NaN  0.019878  0.019878  NaN    tonnes/annum  \n",
      "3  NaN  0.020946  0.020946  NaN    tonnes/annum  \n",
      "4  NaN  0.020105  0.020105  NaN    tonnes/annum  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "file_mean = \"/Users/dianenacario/scikit_learn_data/uol_group_d/datasets_mean_median/LAEI_2019_NA_FILLED_WITH_MEAN.csv\"\n",
    "file_median = \"/Users/dianenacario/scikit_learn_data/uol_group_d/datasets_mean_median/LAEI_2019_NA_FILLED_WITH_MEDIAN.csv\"\n",
    "\n",
    "# Load the datasets\n",
    "mean_df = pd.read_csv(file_mean)\n",
    "median_df = pd.read_csv(file_median)\n",
    "\n",
    "# Check the first few rows of each dataset\n",
    "print(\"Data with Mean Imputation:\\n\", mean_df.head())\n",
    "print(\"\\nData with Median Imputation:\\n\", median_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1187b0f2-34d0-45c8-89cf-20610ca1924d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Data (Mean Imputation):\n",
      "         Year  Grid ID 2019  LAEI 1km2 ID  Easting  Northing  Borough     Zone  \\\n",
      "285264  2019             1          5910   510500    203500  Non GLA  Non GLA   \n",
      "285265  2019             2          5911   511500    203500  Non GLA  Non GLA   \n",
      "285266  2019             3          5912   512500    203500  Non GLA  Non GLA   \n",
      "285267  2019             4          5915   515500    203500  Non GLA  Non GLA   \n",
      "285268  2019             5          5916   516500    203500  Non GLA  Non GLA   \n",
      "\n",
      "       Main Source Category   Sector        Source  ...  n2o  nh3  nmvoc  nox  \\\n",
      "285264             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "285265             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "285266             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "285267             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "285268             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "\n",
      "        pb  pcb      pm10     pm2.5  so2  Emissions Unit  \n",
      "285264 NaN  NaN  0.021923  0.021923  NaN    tonnes/annum  \n",
      "285265 NaN  NaN  0.017965  0.017965  NaN    tonnes/annum  \n",
      "285266 NaN  NaN  0.022718  0.022718  NaN    tonnes/annum  \n",
      "285267 NaN  NaN  0.023939  0.023939  NaN    tonnes/annum  \n",
      "285268 NaN  NaN  0.022977  0.022977  NaN    tonnes/annum  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "Filtered Data (Median Imputation):\n",
      "         Year  Grid ID 2019  LAEI 1km2 ID  Easting  Northing  Borough     Zone  \\\n",
      "285264  2019             1          5910   510500    203500  Non GLA  Non GLA   \n",
      "285265  2019             2          5911   511500    203500  Non GLA  Non GLA   \n",
      "285266  2019             3          5912   512500    203500  Non GLA  Non GLA   \n",
      "285267  2019             4          5915   515500    203500  Non GLA  Non GLA   \n",
      "285268  2019             5          5916   516500    203500  Non GLA  Non GLA   \n",
      "\n",
      "       Main Source Category   Sector        Source  ...  n2o  nh3  nmvoc  nox  \\\n",
      "285264             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "285265             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "285266             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "285267             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "285268             Domestic  Biomass  Wood Burning  ...  NaN  NaN    NaN  NaN   \n",
      "\n",
      "        pb  pcb      pm10     pm2.5  so2  Emissions Unit  \n",
      "285264 NaN  NaN  0.021923  0.021923  NaN    tonnes/annum  \n",
      "285265 NaN  NaN  0.017965  0.017965  NaN    tonnes/annum  \n",
      "285266 NaN  NaN  0.022718  0.022718  NaN    tonnes/annum  \n",
      "285267 NaN  NaN  0.023939  0.023939  NaN    tonnes/annum  \n",
      "285268 NaN  NaN  0.022977  0.022977  NaN    tonnes/annum  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter dataset to include only years 2013, 2016, and 2019 for training\n",
    "train_data_mean = mean_df[mean_df['Year'].isin([2013, 2016, 2019])]\n",
    "train_data_median = median_df[median_df['Year'].isin([2013, 2016, 2019])]\n",
    "\n",
    "# Check if filtering worked\n",
    "print(\"Filtered Data (Mean Imputation):\\n\", train_data_mean.head())\n",
    "print(\"Filtered Data (Median Imputation):\\n\", train_data_median.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54f16abd-dc87-49f2-b692-37c013f5bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process Categorical Variables\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the Label Encoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Encode 'Main Source Category' using explicit row and column indexing\n",
    "train_data_mean.loc[:, \"main_source_encoded\"] = encoder.fit_transform(train_data_mean.loc[:, \"Main Source Category\"])\n",
    "train_data_median.loc[:, \"main_source_encoded\"] = encoder.fit_transform(train_data_median.loc[:, \"Main Source Category\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9062cf4a-b2f5-49a1-af6b-934d3f284464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the mean for the mean-imputed dataset\n",
    "for col in [\"nox\", \"pm10\", \"pm2.5\", \"co2\"]:\n",
    "    train_data_mean.loc[:, col] = train_data_mean[col].fillna(train_data_mean[col].mean())\n",
    "\n",
    "# Fill missing values with the median for the median-imputed dataset\n",
    "for col in [\"nox\", \"pm10\", \"pm2.5\", \"co2\"]:\n",
    "    train_data_median.loc[:, col] = train_data_median[col].fillna(train_data_median[col].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5cb93c3-3736-449d-8590-9db2842dfe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Data for Model Training\n",
    "# Define the years for training and testing\n",
    "train_years = [2013, 2016, 2019]\n",
    "test_year = 2025\n",
    "\n",
    "# Define the pollutants to predict\n",
    "pollutants = [\"nox\", \"pm10\", \"pm2.5\", \"co2\"]\n",
    "\n",
    "# Prepare the features (X) by dropping target variables and Year\n",
    "X_train_mean = train_data_mean[train_data_mean[\"Year\"].isin(train_years)].drop(columns=pollutants + [\"Year\"])\n",
    "X_test_mean = train_data_mean[train_data_mean[\"Year\"] == test_year].drop(columns=pollutants + [\"Year\"])\n",
    "\n",
    "X_train_median = train_data_median[train_data_median[\"Year\"].isin(train_years)].drop(columns=pollutants + [\"Year\"])\n",
    "X_test_median = train_data_median[train_data_median[\"Year\"] == test_year].drop(columns=pollutants + [\"Year\"])\n",
    "\n",
    "# Prepare the target variables (y) for both the training and testing sets\n",
    "# Using a dictionary to store the targets for each pollutant\n",
    "y_train_mean = {pollutant: train_data_mean[train_data_mean[\"Year\"].isin(train_years)][pollutant] for pollutant in pollutants}\n",
    "y_test_mean = {pollutant: train_data_mean[train_data_mean[\"Year\"] == test_year][pollutant] for pollutant in pollutants}\n",
    "\n",
    "y_train_median = {pollutant: train_data_median[train_data_median[\"Year\"].isin(train_years)][pollutant] for pollutant in pollutants}\n",
    "y_test_median = {pollutant: train_data_median[train_data_median[\"Year\"] == test_year][pollutant] for pollutant in pollutants}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24430ab8-6994-472d-a448-b48167b78108",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-Hot Encoding of Categorical Variables\n",
    "# Since the Main Source Category and potentially other categorical variables are present, \n",
    "# we need to encode these for model training using One-Hot Encoding\n",
    "\n",
    "# One-Hot Encode the categorical variables in both training and testing sets\n",
    "X_train_mean_encoded = pd.get_dummies(X_train_mean, drop_first=True)\n",
    "X_test_mean_encoded = pd.get_dummies(X_test_mean, drop_first=True)\n",
    "\n",
    "X_train_median_encoded = pd.get_dummies(X_train_median, drop_first=True)\n",
    "X_test_median_encoded = pd.get_dummies(X_test_median, drop_first=True)\n",
    "\n",
    "# Ensure the columns in the training and testing sets match\n",
    "X_train_mean_encoded, X_test_mean_encoded = X_train_mean_encoded.align(X_test_mean_encoded, join='left', axis=1, fill_value=0)\n",
    "X_train_median_encoded, X_test_median_encoded = X_train_median_encoded.align(X_test_median_encoded, join='left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26e867b6-fdb8-4e18-a664-22ed7882d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the target variables (y) for both the training and testing sets\n",
    "pollutants = [\"nox\", \"pm10\", \"pm2.5\", \"co2\"]\n",
    "\n",
    "y_train_mean = {pollutant: train_data_mean[train_data_mean[\"Year\"].isin(train_years)][pollutant] for pollutant in pollutants}\n",
    "y_test_mean = {pollutant: train_data_mean[train_data_mean[\"Year\"] == test_year][pollutant] for pollutant in pollutants}\n",
    "\n",
    "y_train_median = {pollutant: train_data_median[train_data_median[\"Year\"].isin(train_years)][pollutant] for pollutant in pollutants}\n",
    "y_test_median = {pollutant: train_data_median[train_data_median[\"Year\"] == test_year][pollutant] for pollutant in pollutants}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeac6753-9f9e-421f-a7d5-a26a260fc67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and saving completed for pollutant: nox\n",
      "Training and saving completed for pollutant: pm10\n",
      "Training and saving completed for pollutant: pm2.5\n",
      "Training and saving completed for pollutant: co2\n"
     ]
    }
   ],
   "source": [
    "### Train Random Forest Model for each pollutants\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import joblib  # To save the models\n",
    "\n",
    "# Define pollutants to train the model for\n",
    "pollutants = [\"nox\", \"pm10\", \"pm2.5\", \"co2\"]\n",
    "\n",
    "# Function to train and save Random Forest for each pollutant\n",
    "def train_rf_for_all_pollutants(X_train_mean, X_train_median, train_data_mean, train_data_median, pollutants):\n",
    "    # Store the models for each pollutant\n",
    "    models_mean = {}\n",
    "    models_median = {}\n",
    "\n",
    "    for pollutant in pollutants:\n",
    "        # Prepare the target variable for the current pollutant\n",
    "        y_train_mean = train_data_mean[train_data_mean[\"Year\"].isin([2013, 2016, 2019])][pollutant]\n",
    "        y_train_median = train_data_median[train_data_median[\"Year\"].isin([2013, 2016, 2019])][pollutant]\n",
    "\n",
    "        # Apply One-Hot Encoding to the training sets\n",
    "        X_train_mean_encoded = pd.get_dummies(X_train_mean, drop_first=True)\n",
    "        X_train_median_encoded = pd.get_dummies(X_train_median, drop_first=True)\n",
    "\n",
    "        # Train the model using the mean-imputed dataset\n",
    "        rf_model_mean = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        rf_model_mean.fit(X_train_mean_encoded, y_train_mean)\n",
    "        models_mean[pollutant] = rf_model_mean  # Save the trained model\n",
    "        \n",
    "        # Save the mean-imputed model to disk\n",
    "        joblib.dump(rf_model_mean, f'rf_model_mean_{pollutant}.pkl')\n",
    "\n",
    "        # Train the model using the median-imputed dataset\n",
    "        rf_model_median = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        rf_model_median.fit(X_train_median_encoded, y_train_median)\n",
    "        models_median[pollutant] = rf_model_median  # Save the trained model\n",
    "        \n",
    "        # Save the median-imputed model to disk\n",
    "        joblib.dump(rf_model_median, f'rf_model_median_{pollutant}.pkl')\n",
    "\n",
    "        print(f\"Training and saving completed for pollutant: {pollutant}\")\n",
    "\n",
    "    return models_mean, models_median\n",
    "\n",
    "# Prepare the training features (X_train) from 2013, 2016, and 2019\n",
    "X_train_mean = train_data_mean[train_data_mean[\"Year\"].isin([2013, 2016, 2019])].drop(columns=pollutants + [\"Year\"])\n",
    "X_train_median = train_data_median[train_data_median[\"Year\"].isin([2013, 2016, 2019])].drop(columns=pollutants + [\"Year\"])\n",
    "\n",
    "# Train Random Forest models for each pollutant and save them\n",
    "models_mean, models_median = train_rf_for_all_pollutants(X_train_mean, X_train_median, train_data_mean, train_data_median, pollutants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990671fd-3db9-4550-af9c-cab31a2341e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Define file paths for the datasets\n",
    "file_mean = \"/Users/dianenacario/scikit_learn_data/uol_group_d/datasets_mean_median/LAEI_2019_NA_FILLED_WITH_MEAN.csv\"\n",
    "file_median = \"/Users/dianenacario/scikit_learn_data/uol_group_d/datasets_mean_median/LAEI_2019_NA_FILLED_WITH_MEDIAN.csv\"\n",
    "\n",
    "# Reload the datasets\n",
    "train_data_mean = pd.read_csv(file_mean)\n",
    "train_data_median = pd.read_csv(file_median)\n",
    "\n",
    "# Define pollutants to predict\n",
    "pollutants = [\"nox\", \"pm10\", \"pm2.5\", \"co2\"]\n",
    "\n",
    "# Load the trained models from the saved files\n",
    "models_mean = {}\n",
    "models_median = {}\n",
    "\n",
    "for pollutant in pollutants:\n",
    "    models_mean[pollutant] = joblib.load(f'rf_model_mean_{pollutant}.pkl')\n",
    "    models_median[pollutant] = joblib.load(f'rf_model_median_{pollutant}.pkl')\n",
    "\n",
    "print(\"Models successfully loaded!\")\n",
    "\n",
    "# Generate input features for 2025 using the mean and median of the historical data (2013, 2016, 2019)\n",
    "X_2025_mean = train_data_mean[train_data_mean[\"Year\"].isin([2013, 2016, 2019])].drop(columns=pollutants + [\"Year\"]).mean().values.reshape(1, -1)\n",
    "X_2025_median = train_data_median[train_data_median[\"Year\"].isin([2013, 2016, 2019])].drop(columns=pollutants + [\"Year\"]).median().values.reshape(1, -1)\n",
    "\n",
    "# Apply One-Hot Encoding to the 2025 data\n",
    "X_2025_mean_encoded = pd.get_dummies(pd.DataFrame([X_2025_mean]), drop_first=True)\n",
    "X_2025_median_encoded = pd.get_dummies(pd.DataFrame([X_2025_median]), drop_first=True)\n",
    "\n",
    "# Ensure the columns match the training set encoding\n",
    "X_2025_mean_encoded, _ = X_2025_mean_encoded.align(X_train_mean_encoded, join='left', axis=1, fill_value=0)\n",
    "X_2025_median_encoded, _ = X_2025_median_encoded.align(X_train_median_encoded, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Predict pollutant levels for 2025 using both mean and median-imputed models\n",
    "predictions_2025_mean = {}\n",
    "predictions_2025_median = {}\n",
    "\n",
    "for pollutant in pollutants:\n",
    "    # Predict using the mean-imputed model\n",
    "    predictions_2025_mean[pollutant] = models_mean[pollutant].predict(X_2025_mean_encoded)\n",
    "    \n",
    "    # Predict using the median-imputed model\n",
    "    predictions_2025_median[pollutant] = models_median[pollutant].predict(X_2025_median_encoded)\n",
    "\n",
    "# Display predictions for each pollutant\n",
    "for pollutant in pollutants:\n",
    "    print(f\"Predicted {pollutant} for 2025 (Mean Imputed): {predictions_2025_mean[pollutant][0]}\")\n",
    "    print(f\"Predicted {pollutant} for 2025 (Median Imputed): {predictions_2025_median[pollutant][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d8827b-32bd-4486-94f4-578d08dd3cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[SL]LMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
